{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "import collections\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from cdlib import evaluation\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "    Creates the benchmark network\n",
    "    The seed parameter is not passed to create a different network all the time\n",
    "    Sometimes if fails to create the network, so we give it a max of 30 times\n",
    "'''\n",
    "def create_benchmark_graph(n, tau1, tau2, mu, average_degree, min_community):\n",
    "    count = 0\n",
    "    num_tries = 30\n",
    "    \n",
    "    while count < num_tries:\n",
    "        try:\n",
    "            G = LFR_benchmark_graph(\n",
    "                n, tau1, tau2, mu, average_degree=average_degree, \\\n",
    "                    min_community=min_community\n",
    "            )\n",
    "            return G\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            count +=1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    All possible configuration we want to run our experiments\n",
    "'''\n",
    "configuration = {\n",
    "    'n':[500,1581,5000,15811,50000], \n",
    "    'tau1': [3],\n",
    "    'tau2': [1.5],\n",
    "    'mu': [0.1],\n",
    "    'avg_degree': [10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n': 500, 'tau1': 3, 'tau2': 1.5, 'mu': 0.1, 'avg_degree': 10}\n",
      "{'n': 1581, 'tau1': 3, 'tau2': 1.5, 'mu': 0.1, 'avg_degree': 10}\n",
      "{'n': 5000, 'tau1': 3, 'tau2': 1.5, 'mu': 0.1, 'avg_degree': 10}\n",
      "{'n': 15811, 'tau1': 3, 'tau2': 1.5, 'mu': 0.1, 'avg_degree': 10}\n",
      "{'n': 50000, 'tau1': 3, 'tau2': 1.5, 'mu': 0.1, 'avg_degree': 10}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "configurations_possible = []\n",
    "\n",
    "'''\n",
    "    creates all the possible configuration objects taking the object\n",
    "    configuration into account\n",
    "'''\n",
    "def get_possible_configs(conf, index, current):\n",
    "\n",
    "    if index == len(conf):\n",
    "        configurations_possible.append(current.copy())\n",
    "        print(current)\n",
    "        return \n",
    "\n",
    "    here = list(conf.keys())[index]\n",
    "\n",
    "    for value in conf[here]:\n",
    "        current[here] = value\n",
    "        get_possible_configs(conf, index + 1, current)\n",
    "\n",
    "\n",
    "get_possible_configs(configuration, 0, {})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import community.community_louvain as community_louvain\n",
    "import math\n",
    "\n",
    "#from cdlib import algorithms\n",
    "#import cdlib\n",
    "\n",
    "'''\n",
    "    Get the different dictionaries of the communities created by the LRF and \n",
    "    the ones gotten by runing the louvain algorithm\n",
    "    Each dictionary key is going to correspond to a id of the community\n",
    "'''\n",
    "def get_communities(G):\n",
    "\n",
    "    communities = {frozenset(G.nodes[v][\"community\"]) for v in G}\n",
    "\n",
    "\n",
    "    # (com_nr, set community)\n",
    "    lrf_dict = defaultdict()\n",
    "    c = 1\n",
    "    for y in communities:\n",
    "        lrf_dict[c] = y\n",
    "        c+= 1\n",
    "\n",
    "\n",
    "    # (comm_nr, set communities)\n",
    "    partion = community_louvain.best_partition(G)\n",
    "    louvain_dict = defaultdict(set)\n",
    "\n",
    "\n",
    "    for node, community in partion.items():\n",
    "        louvain_dict[community].add(node) # (community_nr, nodes)\n",
    "\n",
    "    #x1 = cdlib.NodeClustering(list(louvain_dict.values()), G)\n",
    "    #x2 = cdlib.NodeClustering(list(lrf_dict.values()), G)\n",
    "    #print(evaluation.normalized_mutual_information(x1, x2))\n",
    "\n",
    "\n",
    "    return lrf_dict, louvain_dict\n",
    "\n",
    "\n",
    "'''\n",
    "    Having a set of community ids returns all the nodes of those communities\n",
    "'''\n",
    "def get_percentage_union(set_ids, mapping_ids):\n",
    "\n",
    "    z = set()\n",
    "    for id in set_ids:\n",
    "        z = z.union(mapping_ids[id])\n",
    "    return z\n",
    "\n",
    "\n",
    "'''\n",
    "    Checks if a community is considered small according to the value expected for the\n",
    "    resolution limit to appear - sqt(2*m)\n",
    "'''\n",
    "def is_small_community(G, community):\n",
    "    res_limit_val = math.sqrt(2*G.number_of_edges())\n",
    "    sub = G.subgraph(community)\n",
    "    return sub.number_of_edges() < res_limit_val\n",
    "\n",
    "\n",
    "'''\n",
    "    Returns the percentage between the identified communities that suffer from the resolution limit and\n",
    "    the total number of identified communities\n",
    "'''\n",
    "def compare_communities_stats(G, threshold):\n",
    "\n",
    "    lrf_dict, louvain_dict = get_communities(G)\n",
    "\n",
    "    assigned_ones = defaultdict(set)# sets from the louvain that are assigned as most similar to the same set of the lrf\n",
    "\n",
    "    for k, y in lrf_dict.items():\n",
    "        \n",
    "        higher = -1\n",
    "        target_set = set() # set with the most common nodes\n",
    "        overlapping_set_nr = set()\n",
    "\n",
    "        for nr, com_set in louvain_dict.items():\n",
    "\n",
    "            temp = com_set & y\n",
    "            \n",
    "            if len(temp) > 0:\n",
    "                overlapping_set_nr.add(nr)\n",
    "                assigned_ones[nr].add(k)\n",
    "\n",
    "            \n",
    "            if higher < len(temp):\n",
    "                higher = len(temp)\n",
    "\n",
    "        louvain_union = get_percentage_union(overlapping_set_nr, louvain_dict)\n",
    "        lrf_union = lrf_dict[k]\n",
    "        percentage = len(louvain_union.intersection(lrf_union)) / max(len(louvain_union), len(lrf_union))\n",
    "        #print(\"For lrf community with size {}, there were found in louvain {} communities overlapping\".format(len(y), len(overlapping_set_nr)))\n",
    "        #print(\"For lrf community id {} (resol_lim : {}), they intersect with louvain communities ids {} => {}\".format(k,\\\n",
    "        #is_small_community(G, lrf_union) ,overlapping_set_nr, percentage))\n",
    "\n",
    "    counter = 0\n",
    "    total = 0\n",
    "    print(\"the other way around:\")\n",
    "    for k, y in assigned_ones.items(): \n",
    "        temp = []\n",
    "        # k -> community id of louvain\n",
    "        # y -> set of communities id of lrf\n",
    "        # community id of louvain -> communties of lrf that overlap with the louvain\n",
    "        louvain_union = louvain_dict[k]\n",
    "        lrf_union = get_percentage_union(y, lrf_dict)\n",
    "        percentage = len(louvain_union.intersection(lrf_union)) / max(len(louvain_union), len(lrf_union))\n",
    "        #print(\"{} (louvain (resol_lim : {})) : {} (lrf) => {}\" .format(k, is_small_community(G, louvain_union), y, percentage))\n",
    "\n",
    "        for v in y:\n",
    "            if len(lrf_dict[v] & louvain_union) / len(lrf_dict[v]) >= threshold:\n",
    "                temp.append(v)\n",
    "                total +=1\n",
    "        \n",
    "        if len(temp) > 1:\n",
    "            #print(k, \"=>\", len(temp))\n",
    "            counter += len(temp) #- 1\n",
    "            #print(v, len(lrf_dict[v] & louvain_union) / len(lrf_dict[v]) )\n",
    "\n",
    "    #print(\"counter total\", counter, \"|\", len(lrf_dict), \"|\", counter/ len(lrf_dict))\n",
    "\n",
    "    #print(\"counter2 total\", counter, \"|\", total, \"|\", counter/total)\n",
    "\n",
    "    if total == 0:\n",
    "        return 0\n",
    "        \n",
    "    return counter/total\n",
    "\n",
    "'''\n",
    "    Compares the number of communities generated by the LRF-benchmark\n",
    "    algorithm and the ones found by the louvain algorithm\n",
    "'''\n",
    "def compare_communities_number(G):\n",
    "    partion = community_louvain.best_partition(G)\n",
    "    l_c = max(partion.values())\n",
    "\n",
    "    communities = {frozenset(G.nodes[v][\"community\"]) for v in G}\n",
    "    lrf_c = len(communities)\n",
    "\n",
    "    return l_c , lrf_c\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Compares the community size distribution between the ones created by the louvain algorithm and \n",
    "    the lrf-benchmark algorithm. It also shows where the lower bound of the resolution limit stands\n",
    "'''\n",
    "def community_size_distribution(G):\n",
    "    lrf_dict, louvain_dict = get_communities(G)\n",
    "    counter=collections.Counter([G.subgraph(x).number_of_edges() for x in lrf_dict.values()])\n",
    "    counter2=collections.Counter([G.subgraph(x).number_of_edges() for x in louvain_dict.values()])\n",
    "    res_limit_val = math.sqrt(G.number_of_edges()/2)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    plt.hist(counter,bins=20,alpha=0.6, label='LFR')\n",
    "    plt.hist(counter2,bins=20,alpha=0.6, label='Louvain')\n",
    "    plt.axvline(x=res_limit_val, color= 'black',linewidth=2,linestyle='--')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx.algorithms.community as nxcomm\n",
    "\n",
    "'''\n",
    "    Calculates the percentage difference of the modularity between the louvain and the\n",
    "    lrf-benchmark algorithm\n",
    "'''\n",
    "def modularity_dif(G):\n",
    "    lrf_dict, louvain_dict = get_communities(G)\n",
    "    mod_louvain = nxcomm.modularity(G,louvain_dict.values())\n",
    "    mod_lfr = nxcomm.modularity(G,lrf_dict.values())\n",
    "    #print(louvain_dict.values())\n",
    "    #print(lrf_dict.values())\n",
    "    #print(((mod_lfr-mod_louvain)*100)/abs((mod_louvain+mod_lfr)/2))\n",
    "    return (((mod_lfr-mod_louvain)*100)/abs((mod_louvain+mod_lfr)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Accepts a list of configuration and a callback function and runs the callback function\n",
    "    for all those possible configurations\n",
    "'''\n",
    "def run_experiment(configurations_possible, experiment_call_back):\n",
    "\n",
    "    values = []\n",
    "    for configuration in configurations_possible:\n",
    "        print(configuration)\n",
    "        G = create_benchmark_graph(configuration['n'], configuration['tau1'], \\\n",
    "            configuration['tau2'], configuration['mu'], \\\n",
    "            average_degree=configuration['avg_degree'], min_community=40)\n",
    "        values.append(experiment_call_back(G))\n",
    "        #print(values)\n",
    "    \n",
    "    #print(values)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os.path import exists\n",
    "\n",
    "'''\n",
    "    runs the \"run_experiment\" function \"times\" times and stores those results in \n",
    "    a npy file\n",
    "'''\n",
    "def total_results(times,experiment_callback,path):\n",
    "    if exists(path):\n",
    "        results = np.load(path).tolist()\n",
    "    else:\n",
    "        results = []\n",
    "    #print(len(results))\n",
    "    i = 0\n",
    "    while i < times:\n",
    "        try:\n",
    "            res = run_experiment(configurations_possible, experiment_callback)\n",
    "            for j in range(len(res)):\n",
    "                if len(results) <= j:\n",
    "                    results.append([res[j]])\n",
    "                else:\n",
    "                    results[j].append(res[j])\n",
    "            np.save(path,results)\n",
    "            i+=1\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "'''\n",
    "    By receiving a np array it calculate the t-distribution of that array with a 95% confidence level\n",
    "'''\n",
    "def get_intervals(res):\n",
    "    intervals = []\n",
    "    for data in res:\n",
    "        if np.all(data == data[0]):\n",
    "            intervals.append((data[0],data[0]))\n",
    "        else:\n",
    "            intervals.append(st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data)))\n",
    "    #intervals = [st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data)) for data in res]\n",
    "    return intervals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "    Plots the values of our metric by showing the average and confidence intervals for each value\n",
    "    It can also use the log scale and the chart can also be saved in the computer storage system\n",
    "'''\n",
    "def show_plot(x_values,intervals,mixing_param,metric= 'CCR', path='',x_log = False):\n",
    "    y = [(x[0]+x[1])/2 for x in intervals]\n",
    "    yerr = [(x[1]-x[0]) for x in intervals]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.errorbar(x_values, y, yerr=yerr, fmt='x--')\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    if x_log:\n",
    "        plt.xscale('log')\n",
    "    plt.xlabel(mixing_param)\n",
    "    plt.ylabel(metric)\n",
    "    #plt.ylim(0)\n",
    "    if path != '':\n",
    "        plt.savefig(path+'.pgf')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the path accordingly\n",
    "res = total_results(times = 20,experiment_callback = modularity_dif ,path='results/values/nodes_mod_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_degree = np.load('average_degree.npy')\n",
    "print(res_degree.shape)\n",
    "intervals_degree = get_intervals(res_degree)\n",
    "show_plot([6,10,14,18,22],intervals_degree,'<k>',path='results/pgf/mixing_k') #20000 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_nodes = np.load('nodes.npy')\n",
    "print(res_nodes.shape)\n",
    "intervals_nodes = get_intervals(res_nodes)\n",
    "show_plot([500,1581,5000,15811,50000],intervals_nodes,'N',x_log=True,path='results/pgf/mixing_N') #avg_degree 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_degree = np.load('mu.npy')\n",
    "print(res_degree.shape)\n",
    "intervals_degree = get_intervals(res_degree)\n",
    "show_plot([0.1,0.2,0.3,0.4,0.5],intervals_degree,'$\\mu$',path='results/pgf/mixing_mu') #avg_degree 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_degree = np.load('tau1.npy')\n",
    "print(res_degree.shape)\n",
    "intervals_degree = get_intervals(res_degree)\n",
    "show_plot([2.6,2.7,2.8,2.9,3],intervals_degree,'$\\gamma$',path='results/pgf/mixing_tau1') #avg_degree 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_degree = np.load('tau2.npy')\n",
    "print(res_degree.shape)\n",
    "intervals_degree = get_intervals(res_degree)\n",
    "show_plot([1.2,1.4,1.6,1.8,2],intervals_degree,'$B$',path='results/pgf/mixing_tau2')  #avg_degree 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_degree = np.load('nodes_mod.npy')\n",
    "print(res_degree)\n",
    "intervals_degree = get_intervals(res_degree)\n",
    "show_plot([500,1581,5000,15811,50000],intervals_degree,'N',x_log=True,metric='Modularity Diference (%)',path='results/pgf/gmixing_N_mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_degree = np.load('average_degree_mod.npy')\n",
    "print(res_degree.shape)\n",
    "intervals_degree = get_intervals(res_degree)\n",
    "show_plot([6,10,14,18,22],intervals_degree,'<k>',metric='Modularity Diference (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_lfr=[]\n",
    "counter_louvain=[]\n",
    "res_limit_val = []\n",
    "\n",
    "'''\n",
    "    Obtain the values for the distribution of the number of internal links per community graph for the louvain and\n",
    "    lrf-benchmark algorithm\n",
    "'''\n",
    "def mu_distribution():\n",
    "    counter_lfr=[]\n",
    "    counter_louvain=[]\n",
    "    res_limit_val = []\n",
    "    for configuration in configurations_possible:\n",
    "        print(configuration)\n",
    "        G = create_benchmark_graph(configuration['n'], configuration['tau1'], \\\n",
    "            configuration['tau2'], configuration['mu'], \\\n",
    "            average_degree=configuration['avg_degree'], min_community=40)\n",
    "        lrf_dict, louvain_dict = get_communities(G)\n",
    "        counter_lfr.append(collections.Counter([G.subgraph(x).number_of_edges() for x in lrf_dict.values()]))\n",
    "        counter_louvain.append(collections.Counter([G.subgraph(x).number_of_edges() for x in louvain_dict.values()]))\n",
    "        res_limit_val.append(math.sqrt(G.number_of_edges()/2))\n",
    "    return counter_lfr,counter_louvain,res_limit_val\n",
    "counter_lfr,counter_louvain,res_limit_val = mu_distribution() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Plot the graph  for the distribution of the number of internal links per community graph for the louvain and\n",
    "    lrf-benchmark algorithm\n",
    "'''\n",
    "def mu_distribution_plot():\n",
    "    fig, axs = plt.subplots(2, 2,figsize=(9,7))\n",
    "\n",
    "    bins=np.histogram(np.hstack((list(counter_lfr[0].keys()),list(counter_louvain[0].keys()))), bins=30)[1]\n",
    "    axs[0,0].hist(counter_lfr[0],bins=bins,alpha=0.6, label='LFR')\n",
    "    axs[0,0].hist(counter_louvain[0],bins=bins,alpha=0.6, label='Louvain')\n",
    "    axs[0,0].axvline(x=res_limit_val[0], color= 'black',linewidth=1,linestyle='--')\n",
    "    axs[0,0].text(0.6, 0.6, '$\\mu = 0.2$', fontsize=13, transform=axs[0,0].transAxes)\n",
    "    axs[0,0].set_yscale('log')\n",
    "    axs[0,0].legend(loc='upper right')\n",
    "\n",
    "    bins=np.histogram(np.hstack((list(counter_lfr[1].keys()),list(counter_louvain[1].keys()))), bins=30)[1]\n",
    "    axs[0,1].hist(counter_lfr[1],bins=bins,alpha=0.6, label='LFR')\n",
    "    axs[0,1].hist(counter_louvain[1],bins=bins,alpha=0.6, label='Louvain')\n",
    "    axs[0,1].axvline(x=res_limit_val[1], color= 'black',linewidth=1,linestyle='--')\n",
    "    axs[0,1].text(0.6, 0.6, '$\\mu = 0.3$', fontsize=13, transform=axs[0,1].transAxes)\n",
    "    axs[0,1].set_yscale('log')\n",
    "    axs[0,1].legend(loc='upper right')\n",
    "\n",
    "    bins=np.histogram(np.hstack((list(counter_lfr[2].keys()),list(counter_louvain[2].keys()))), bins=30)[1]\n",
    "    axs[1,0].hist(counter_lfr[2],bins=bins,alpha=0.6, label='LFR')\n",
    "    axs[1,0].hist(counter_louvain[2],bins=bins,alpha=0.6, label='Louvain')\n",
    "    axs[1,0].axvline(x=res_limit_val[2], color= 'black',linewidth=1,linestyle='--')\n",
    "    axs[1,0].text(0.6, 0.6, '$\\mu = 0.4$', fontsize=13, transform=axs[1,0].transAxes)\n",
    "    axs[1,0].set_yscale('log')\n",
    "    axs[1,0].legend(loc='upper right')\n",
    "\n",
    "    bins=np.histogram(np.hstack((list(counter_lfr[3].keys()),list(counter_louvain[3].keys()))), bins=30)[1]\n",
    "    axs[1,1].hist(counter_lfr[3],bins=bins,alpha=0.6, label='LFR')\n",
    "    axs[1,1].hist(counter_louvain[3],bins=bins,alpha=0.6, label='Louvain')\n",
    "    axs[1,1].axvline(x=res_limit_val[3], color= 'black',linewidth=1,linestyle='--')\n",
    "    axs[1,1].text(0.6, 0.6, '$\\mu = 0.5$', fontsize=13, transform=axs[1,1].transAxes)\n",
    "    axs[1,1].set_yscale('log')\n",
    "    axs[1,1].legend(loc='upper right')\n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='Internal links', ylabel='frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mu_distribution_plot()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
